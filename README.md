# ğŸ“š RAG PDF Chatbot

This project is a **Retrieval-Augmented Generation (RAG) PDF Chatbot** built using **Streamlit, LangChain, FAISS, Pinecone, HuggingFace, and Cohere/Groq/OpenAI**.  
It allows users to upload PDFs, process them into **chunks**, create **embeddings**, store them in a vector database (**FAISS/Pinecone**), and then query them using an **LLM** for intelligent answers.

---




Live App: [https://groqragapp.onrender.com/](https://groqragapp.onrender.com/)

## ğŸš€ Features
- ğŸ“¤ Upload PDFs directly in the web app
- ğŸ“‘ Extract and clean text from PDFs (supports scanned PDFs via OCR)
- âœ‚ï¸ Chunking of text into manageable pieces
- ğŸ§© Embedding generation using **Sentence Transformers / Cohere / OpenAI**
- ğŸ—‚ï¸ Store and search chunks in **FAISS or Pinecone**
- ğŸ’¬ Ask questions and get answers powered by **LLMs (Groq / OpenAI / Cohere)**
- ğŸ“Š **Frontend pipeline visualization** showing:
  - âœ… File uploaded  
  - âš™ï¸ PDF loaded  
  - âœ‚ï¸ Chunking  
  - ğŸ§© Embedding  
  - ğŸ’¾ Storing in Vector DB  
  - ğŸ¤– Ready to Chat!  

---

## ğŸ› ï¸ Tech Stack
- [Streamlit](https://streamlit.io/) â€“ UI framework
- [LangChain](https://www.langchain.com/) â€“ RAG pipeline
- [FAISS](https://github.com/facebookresearch/faiss) / [Pinecone](https://www.pinecone.io/) â€“ Vector DB
- [Sentence-Transformers](https://www.sbert.net/) â€“ Embedding models
- [Cohere](https://cohere.com/), [Groq](https://groq.com/), [OpenAI](https://openai.com/) â€“ LLM providers
- [PyPDF](https://pypi.org/project/pypdf/) / [Unstructured](https://unstructured-io.github.io/) â€“ PDF parsing
- [Tesseract OCR](https://github.com/tesseract-ocr/tesseract) â€“ OCR for scanned PDFs

---

## ğŸ“‚ Project Structure
```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ model/               # LangChain + VectorDB logic
â”‚   â”œâ”€â”€ routes/              # API endpoints (if needed)
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py               # Streamlit UI
â”‚   â”œâ”€â”€ components/          # UI Components
â”‚
â”œâ”€â”€ .env                     # API keys + environment variables
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md                # Documentation
```

---

## âš™ï¸ Installation

1. **Clone repo**
```bash
git clone https://github.com/yourusername/rag-pdf-chatbot.git
cd rag-pdf-chatbot
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate    # Windows
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Setup environment variables**  
Create a `.env` file in the root directory:
```ini
OPENAI_API_KEY=your_openai_api_key
COHERE_API_KEY=your_cohere_api_key
GROQ_API_KEY=your_groq_api_key
PINECONE_API_KEY=your_pinecone_api_key
```

---

## â–¶ï¸ Run the App
```bash
streamlit run frontend/app.py
```

---

## ğŸ”„ RAG Pipeline (Stepwise)
1. **ğŸ“¤ Upload PDF**
2. **ğŸ“‘ Extract text**
3. **âœ‚ï¸ Chunking**
4. **ğŸ§© Generate embeddings**
5. **ğŸ’¾ Store in FAISS/Pinecone**
6. **ğŸ¤– Query LLM for answers**

---

## ğŸ“¸ Example Frontend Visualization

âœ… File uploaded â†’ âš™ï¸ PDF Loaded â†’ âœ‚ï¸ Chunking â†’ ğŸ§© Embedding â†’ ğŸ’¾ Stored â†’ ğŸ¤– Ready to Chat!  

---

## ğŸ¤ Contributing
Feel free to fork this repo, raise issues, and submit PRs.

---

## ğŸ“œ License
MIT License Â© 2025


## ğŸš€ Demo

Live App: [https://groqragapp.onrender.com/](https://groqragapp.onrender.com/)
